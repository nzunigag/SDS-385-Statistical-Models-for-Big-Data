

# Exercises 1: Preliminaries

The goal of this warm-up assignment is to provide the student with an introduction to optimization and its role in data analysis.  

For this section, please read Chapter 2 of _Numerical Optimization_, by Nocedal and Wright.  The full text of this book is available for free through the [UT Library website](http://lib.utexas.edu).  You should come away with a good general understanding of two methods for optimizing smooth functions:  
1) the method of steepest descent, or simply _gradient descent_, and   
2) Newton's method.  

Feel free to skip the stuff about trust-region methods.  The overview of quasi-Newton methods is nice, but optional for now.  

The exercises for this unit will have you practice these techniques.  They will also will hammer your linear algebra skills.  

# Comments for the Peer-Reviewer

- The solution is presented in a [PDF](solution01-SDS385.pdf) document along with the [Latex](solution01-SDS385.tex) files used. 

- The R code files can be found in this [folder](Ex01R), which also includes the output figures and the database used in Part 2.

- I also included a [literature](Literature) folder, which contains additional readings I used.
