\documentclass[11 pt]{article} 
\usepackage[left=2cm, top=2cm, right=2cm, bottom=2.5cm, footskip=.5cm]{geometry}
\usepackage{graphicx}
\usepackage{subcaption} 
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{url}
\usepackage{booktabs}
\usepackage{units}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{float}
\usepackage{booktabs}
%\usepackage{hyperref}
\usepackage[svgnames]{xcolor}
\definecolor{mygray}{rgb}{0.9,0.9,0.9}
\newcommand{\E}{\mbox{E}}
\newcommand{\prox}{ \mathop{\mathrm{prox}} }
\newcommand{\enorm}[1]{\Vert #1 \Vert_2}
\newcommand{\N}{\mbox{N}}

\lstset{language=R,
	basicstyle=\small\ttfamily,
	stringstyle=\color{DarkGreen},
	otherkeywords={0,1,2,3,4,5,6,7,8,9},
	morekeywords={TRUE,FALSE},
	deletekeywords={data,frame,length,as,character},
	keywordstyle=\color{blue},
	commentstyle=\color{DarkGreen},
	frame=single,
	backgroundcolor=\color{mygray},
	numbers=left, 
}

\author{Natalia Zuniga-Garcia}
\title{Exercises 6 The Proximal Gradient Method}
\date{October 23, 2017}


\begin{document}
	
	\maketitle
	
	In this set of exercises, we learn about the proximal gradient algorithm.  This is our first all-purpose algorithm capable of handling non-smooth terms that enforce sparsity, like an $\ell^1$ regularizer.
	
	\section{Proximal operators}
	
	First, some definitions.  Let $f(x)$ be a convex function.  The \textit{Moreau envelope} $E_{\gamma} f(x)$ and \textit{proximal operator} $\prox_{\gamma} f(x)$ for parameter $\gamma > 0$ are defined as
	\begin{eqnarray}
	E_{\gamma} f(x) &=& \min_{z } \left\{f(z) + \frac{1}{2\gamma} \enorm{z - x}^2  \right\}  \leq f(x) \\
	\prox_{\gamma} f(x) &=& \arg \min_{z } \left\{  f(z)+ \frac{1}{2\gamma} \enorm{z - x}^2  \right\} \, .
	\end{eqnarray}
	Intuitively, the Moreau envelope is a regularized version of $f$.  It approximates $f$ from below, and has the same set of minimizing values as $f$.  The proximal mapping returns the value that solves the little minimization problem defined by the Moreau envelope.  The objective in this little minimization problem balances two goals: minimizing $f$, and staying near $x$.  The proximal operator says \textit{where} the minimum occurs, while the Moreau envelope says what the \textit{value} of the minimum is.
	
	Figure 1 shows a simple one-dimensional example of a Moreau envelope and a proximal operator for the absolute-value function.
	
	\begin{figure}[H]
		\begin{center}
		\includegraphics[width=0.53\linewidth]{moreau_envelope.pdf}
		\caption{\small This picture shows a simple example of a proximal operator and Moreau envelope.  The solid black line shows the function $f(x) = |x|$, and the dotted line shows the corresponding Moreau envelope $E_{\gamma} f (x)$ with parameter $\gamma=1$.  The grey line shows the function 
			$|x| + (1/2)(x-x_0)^2$ for $x_0 = 1.5$, whose minimum (shown as a red cross)
			defines the Moreau envelope and proximal operator.  This point has horizontal coordinate
			$\prox_\gamma f(x_0) = 0.5$ and vertical coordinate $E_{\gamma} f (x) = 1$, and is closer than $x_0$
			to the overall minimum at $x=0$.  The blue circle shows the point 
			$(x_0, E_{\gamma} f (x_0))$; the vertical coordinate of the blue point is precisely the vertical coordinate of the red point, emphasizing the point-wise construction of the Moreau
			envelope in terms of a simple optimization problem.
		}
	\end{center}
	\end{figure}
	
	\begin{enumerate}[label=(\Alph*)]
		\item
		The proximal operator gives a nice interpretation of classical gradient descent.  Consider the local linear approximation of $f(x)$ about a point $x_0$:
		$$
		f(x) \approx \hat{f}(x; x_0) = f(x_0) + (x - x_0)^{(t)} \nabla f(x_0) \, .
		$$
		
		Derive the proximal operator (with parameter $\gamma$) of the linear approximation $\hat{f}(x; x_0)$, and show that this proximal operator is identical to a gradient-descent step for $f(x)$ of size $\gamma$, starting from the point $x_0$.  In reflecting on this answer, make sure you feel comfortable with the following statement: ``the gradient step minimizes a local linear approximation of the function, subject to a quadratic regularizer that keeps the next iterate close to $x_0$ (where, presumably, the linear approximation is reasonable).''
		
		\vspace{2mm}
		\textbf{Solution}
		
		The proximal operator is:
		$$
			\prox_{\gamma} f(x) = \arg \min_{z } \left\{  f(z)+ \frac{1}{2\gamma} \enorm{z - x}^2  \right\} \
		$$
		
		Using the local linear approximation of $f(x)$ about a point $x_0$:
		$$ 			\prox_{\gamma} \hat{f}(x; x_0) = \arg \min_{z } \left\{  f(x_0) + (z - x_0)^{(t)} \nabla f(x_0)+ \frac{1}{2\gamma} \enorm{z - x_0}^2  \right\} 	$$
		
		Now we try to minimize the objective function by calculation its derivative with respect to $z$ and equalizing it to zero as follow,
		$$			\nabla f(x_0) + \frac{1}{\gamma}(z-x_0) = 0 $$
		$$ z = x_0 - \gamma \nabla f(x_0) $$
		
		We can observe that this is  the gradient-descent step of size $\gamma$.


		
		\newpage
		\item Many intermediate steps in statistical optimization problems can be written very compactly in terms of proximal operators of log-likelihoods or penalty functions.  For example, consider a negative log likelihood of the form
		$$
		l(x) = \frac{1}{2} x^{T} P x - q^{T} x + r \, .
		$$
		Show that the proximal operator with parameter $1/\gamma$ of $l(x)$ takes the form
		$$
		\prox_{1/\gamma} l(x) = (P + \gamma I)^{-1} (\gamma  x + q) \, ,
		$$
		assuming the relevant inverse exists. 
		
		\vspace{2mm}
		\textbf{Solution}
		
		The proximal operator with parameter $1/\gamma$ of $l(x)$ is:
		$$
		\prox_{1/\gamma} l(x) =  \arg \min_{z } \left\{  l(z)+ \frac{\gamma}{2} \enorm{z - x}^2  \right\} 
		=  \arg \min_{z } \left\{  \frac{1}{2} z^{T} P z - q^{T} z + r+ \frac{\gamma}{2} \enorm{z - x}^2  \right\} $$
		Now we try to minimize by calculation its derivative with respect to $z$ and equalizing it to zero as follow,
		$$
		0 \stackrel{set}{=}  P z - q+  \gamma (z - x)  $$
		$$
		-Pz - \gamma z =  - q - \gamma x  $$
		$$
		(P + \gamma I) z =  \gamma x + q   $$
		
		Where $I$ is the identity matrix. Assuming that $(P + \gamma I) $ is invertible,
		$$
		z =  (P + \gamma I)^{-1}( \gamma x + q)   $$
		Then, we showed that,
		$$
		prox_{1/\gamma} l(x) =  (P + \gamma I)^{-1}( \gamma x + q)   $$
		
		Then show that if we have a Gaussian sampling model of the form $(y \mid x) \sim \N(Ax, \Omega^{-1})$, then our negative log likelihood can be written in the form given above.  Here $A$ is like our feature matrix, $\Omega$ is a covariance matrix, and $x$ is like a regression vector.\footnote{This is notation from the optimization literature, rather than the stats literature.  It's important to be able to translate between both.}  Specify what $P$, $q$, and $r$ are for this negative log likelihood.
		
		\vspace{2mm}
		\textbf{Solution}
		
		The likelihood of the multivariate Gaussian distribution is:
		$$
		L(y  | x) = (2\pi)^{n/2} |\Omega|^{1/2} exp\left\{-\frac{1}{2} (y - Ax)^T \Omega (y-Ax) \right\} $$
		Then, the negative likelihood function is:
		$$
		l(y  | x) \propto \frac{1}{2} (y - Ax)^T \Omega (y-Ax) 
		= \frac{1}{2} y^T \Omega y + \frac{1}{2}x^t A^T \Omega A x - y^T \Omega A x 
		= \frac{1}{2} x^T Px q^T +r $$
		
		
		Where we obtained:
		$$
		P = A^T \Omega A $$
		$$
		q = -A^T \Omega y $$
		$$
		r =  \frac{1}{2} y^T \Omega y $$

		
		
		\newpage
		\item  Let $\phi(x) = \tau \Vert x \Vert_1$.  Express the proximal operator of this function in terms of the soft-thresholding function that we learned about in the last set of exercises.  (An element-wise expression is fine.)
		
		\vspace{2mm}
		\textbf{Solution}
		
		The proximal operator is:
		$$
		\prox_{\gamma} \phi(x) = \arg \min_{z } \left\{  \phi(z)+ \frac{1}{2\gamma} \enorm{z - x}^2  \right\} = \arg \min_{z } \left\{  \tau \Vert x \Vert_1+ \frac{1}{2\gamma} \enorm{z - x}^2  \right\} $$
		$$
		= \arg \min_{z } \left\{  \tau \sum_{i=1}^{p} \vert z_i \vert + \frac{1}{2\gamma} \enorm{z - x}^2  \right\} 
		$$
		Then we have that for each $z_i$ (element-wise):
		$$
		\arg \min_{z_i } \left\{  \tau \vert z_i \vert + \frac{1}{2\gamma} (z_i - x_i)^2  \right\} = \arg \min_{z_i } \left\{  \frac{1}{2} (z_i - x_i)^2 + \gamma \tau \vert z_i \vert \right\}  $$
		Which is equal to the soft-thresholding function in Exercises 5:
		$$
		S_\lambda(y) = \arg \min_{\theta} \; \frac{1}{2}(y - \theta)^2 + \lambda | \theta |   $$
		Which we probed to be equal to:
		$$
		S_\lambda(y) = \mbox{sign}(y) \cdot (|y| - \lambda)_+ 
		$$
		Thus, the proximal operator can be written as:
		$$
		\prox_{\gamma} \phi(x_i)  = \mbox{sign}(x_i) \cdot (|x_i| - \gamma \tau)_+ 
		$$
	
	\end{enumerate}
	
	\newpage
	\section{The proximal gradient method}
	
	Suppose that we have some objective function that can be expressed as $f(x) = l(x) + \phi(x)$, where $l(x)$ is differentiable but $\phi(x)$ is not.  The proximal gradient method is designed for precisely this situation.
	
	Recall from above the idea of forming a local linear approximation to a function at some point $x_0$ and then adding a quadratic regularizer.  This gave us an interpretation of gradient descent evaluating the proximal operator of our locally linear approximation.
	
	Here, we'll apply this idea to the first term in our objective, $l(x)$. Define
	$$
	l(x) \approx \tilde{l}(x; x_0) = l(x_0) + (x - x_0)^{(t)} \nabla l(x_0) + \frac{1}{2\gamma} \enorm{x - x_0}^2 \, 
	$$
	as our linear approximation to $l(x)$, plus the quadratic regularizer.  Now we add in the $\phi(x)$ term to get the approximation for our original objective:
	\begin{equation}
	\label{eqn:pg_approx}
	f(x) \approx \tilde{f}(x; x_0) = \tilde{l}(x; x_0) + \phi(x)   \, .
	\end{equation}
	
	
	\begin{enumerate}[label=(\Alph*)]
	\item Consider the surrogate optimization problem in which we minimize the approximation $\tilde{f}(x; x_0)$ in Equation \ref{eqn:pg_approx}, in lieu of our original objective $f(x)$. 
	$$
	\hat{x} = \arg \min_x \; \left\{   \tilde{l}(x; x_0) + \phi(x)  \right\} \, .
	$$
	Show that the solution to this problem is of the form
	\begin{equation}
	\label{eqn:pg_xhat}
	\hat{x} = \prox_{\gamma} \phi(u) \, , \quad \mbox{where} \quad u = x_0 - \gamma \nabla l(x_0) \, .
	\end{equation}
	This is just the proximal operator of the non-smooth part of the objective, $\phi(x)$, evaluated at an intermediate gradient-descent step for the smooth part, $l(x)$.
	
	\vspace{2mm}
	\textbf{Solution}
	
	We have that,
	$$
	\hat{x} = \arg \min_x \; \left\{   \tilde{l}(x; x_0) + \phi(x)  \right\} $$
	Then,
	$$
	\hat{x} = \arg \min_x \; \left\{  l(x_0) + (x - x_0)^T \nabla l(x_0) + \frac{1}{2\gamma} \enorm{x - x_0}^2 + \phi(x)  \right\} $$
	$$
	= \arg \min_x \; \left\{ x ^T \nabla l(x_0) + \frac{1}{2\gamma} \enorm{x - x_0}^2 + \phi(x)  \right\} 
	= \arg \min_{x} \left\{  \frac{1}{2\gamma} ||x - x_0||^2_2 - \frac{1}{2\gamma} 2x^T(\gamma \nabla l(x_0))  + \phi(x) \right\} $$
	$$
	= \arg \min_{x} \left\{ \frac{1}{2\gamma} \left[ ||x - x_0||^2_2 - 2x^T(\gamma \nabla l(x_0))  \right] + \phi(x) \right\} $$
	$$
	= \arg \min_{x} \left\{ \frac{1}{2\gamma} \left[ (x - x_0)^T(x - x_0) - 2(x - x_0)^T(\gamma \nabla l(x_0)) + ( \gamma \nabla l(x_0))^T(\gamma \nabla l(x_0)) \right] + \phi(x) \right\} 
	$$
	$$ 	= \arg \min_{x} \left\{ \frac{1}{2\gamma} (x - x_0 + \gamma \nabla l(x_0))^T(x - x_0 + \gamma \nabla l(x_0)) + \phi(x) \right\} $$
	$$
	= \arg \min_{x} \left\{ \frac{1}{2\gamma} \enorm{x - x_0 + \gamma \nabla l(x_0)}^2 + \phi(x) \right\} 
	= \arg \min_{x} \left\{  \phi(x)+ \frac{1}{2\gamma} \enorm{x - (x_0 - \gamma \nabla l(x_0))}^2  \right\} $$
	
	The we have that,
	$$
	= \prox_{\gamma} \phi(x_0 - \gamma \nabla l(x_0)) $$
	$$
	= \prox_{\gamma} \phi(u) $$
	Where, $ u = x_0 - \gamma \nabla l(x_0) $
	
	
	
	\newpage
	\item The \textit{proximal gradient} method is an iterative algorithm in which we repeatedly form the approximation in Equation \ref{eqn:pg_approx} about the current point, and minimize this surrogate function using Equation \ref{eqn:pg_xhat}.  Written concisely,
	$$
	x^{(t+1)} = \prox_{\gamma^{(t)}} \phi(u^{(t)}) \, , \quad u^{(t)} = x^{(t)} - \gamma^{(t)} \nabla l(x^{(t)}) \, .
	$$
	
	Now consider the lasso regression problem:
	$$
	\hat{\beta} = \arg \min_{\beta} \left\{  \enorm{y - X\beta}^2 + \lambda \Vert \beta \Vert_1 \right\} \, .
	$$
	Using the results on proximal operators you've derived already, write down some concise pseudo-code for using the proximal gradient algorithm to minimize this objective.  Identify the primary computational costs of this algorithm.
	
	Now implemement the method and apply it to the diabetes data from last week.  Make sure you track the convergence of the algorithm, i.e.~the objective values over time.  Compare your answers to the answers you get from the package software you used last week (i.e.~\verb|glmnet| or scikit-learn).\footnote{Keep in mind that those packages are using a value of $\lambda$ that is rescaled by a factor of $n$, since they use the loss function
		$$
		\frac{1}{2n} \enorm{y - X\beta}^2  + \lambda \Vert \beta \Vert_1 \, .
		$$
	}
	
	\vspace{2mm}
	\textbf{Solution}
	
	We use proximal gradient to minimize the objective function 
	$$
	\tilde{f}(\beta; \beta_0) = \tilde{l}(\beta; \beta_0) + \phi(\beta) 
	$$
	Where,
	$$
	l(\beta) = \frac{1}{2n} \enorm{y - X\beta}^2 = \frac{1}{2n} (y-X\beta)^T(y-X\beta)$$
	$$
	\nabla l(\beta) = -\frac{1}{n}X^T(y-X\beta)
	$$
	$$
	\phi(\beta) = \lambda \Vert \beta \Vert_1
	$$ 
	
	We have that,
	$$
	\quad u^{(t)} = \beta^{(t)} - \gamma^{(t)} \nabla l(\beta^{(t)}) 
	$$
		Then, the update is:
	$$
	u^{(t)} = \beta^{(t)} + \gamma^{(t)}X^T(y - X\beta^{(t)}) 
	$$
	We also have that,
	$$
	\beta^{(t+1)} = \prox_{\gamma^{(t)}} \phi(u^{(t)}) 
	\beta^{(t+1)} = \prox_{\gamma^{(t)}} \lambda ||u^{(t)}||_1 $$
	Where element-wise we have, $$
	\beta^{(t+1)}_j = sign(u_j^{(t)}) \cdot (|u^{(t)}_j| - \lambda\gamma^{(t)})_+ $$
	Which corresponds to the soft-thresholding function $S_\lambda(u^{(t)}_j)$  .


	
	\newpage
	Pseudo-code for using the proximal gradient algorithm: \\
	\vspace{2mm}
	
	For i in 2 to iteration
	\begin{itemize}
		\item Estimate the gradient $ \nabla l(\beta) = -\frac{1}{n}X^T(y-X\beta) $
		\item Estimate $ u^{(t)} = \beta^{(t)} - \gamma^{(t)} \nabla l(\beta^{(t)}) $
		\item Update $ 	\beta^{(t+1)}_j = S_\lambda(u^{(t)}_j)$
	\end{itemize}
	
	The main computational cost is present in obtaining the gradient due to the matrix multiplication.
		
	
	The method implementation is presented in the file $Part\_2.R$,
	\lstinputlisting[language = R, firstline=6, lastline=95]{R_Code/Part_2.R}
	
	
	\newpage
	\item A cool variation on proximal gradient is called the \textit{accelerated} proximal gradient algorithm.   The following scheme (due to Nesterov, who's super famous in this area) involves a simple extrapolation step based on the previous iteration:
	$$
	\begin{aligned}
	x^{(t+1)} &= \prox_{ \gamma^{(t)}} \phi(u^{(t)}) \, , \quad u^{(t)} =  z^{(t)} - \gamma^{(t)} \nabla l(z^{(t)})  \\
	s^{(t+1)} &= \frac{1 + (1 + 4 s_{t}^2)^{1/2}}{2} \\
	z^{(t+1)} &=  x^{(t+1)} + \left( \frac{s^{(t)} - 1}{s^{(t+1)}} \right) (x^{(t+1)} - x^{(t)}) \, .
	\end{aligned}
	$$
	
	
	
	The first step involves the proximal operator of the penalty function, evaluated not at the previous iterate $x^{(t)}$, but at an extrapolated version of $x^{(t)}$, based on the magnitude of the previous step's update.  In this sense, large steps give ``momentum'' to the next step, where the amount of momentum is modulated by the scalar $s^{(t)}$ terms.
	
	Implement this acceleration scheme in your proximal gradient code, and compare its convergence speed to that of the unacceleration version.  Does the value of the objective goes down at each and every step?  Do you get to the minimum faster?
	
	Note: you can use this acceleration trick in ordinary gradient descent, too.
	
	\vspace{2mm}
	\textbf{Solution}
	
	Pseudo-code for using the accelerated proximal gradient algorithm: \\
	\vspace{2mm}
	
	For i in 2 to iteration
	\begin{itemize}
		\item Estimate the gradient $ \nabla l(\beta) = -\frac{1}{n}X^T(y-X\beta) $
		\item Estimate $s^{(t+1)} = \frac{1 + (1 + 4 s_{t}^2)^{1/2}}{2}$
		\item Estimate $ u^{(t)} = z^{(t)} - \gamma^{(t)} \nabla l(\beta^{(t)}) $
		\item Update $ \beta^{(t+1)}_j = S_\lambda(u^{(t)}_j)$
		\item Estimate $z^{(t+1)} =  x^{(t+1)} + \left( \frac{s^{(t)} - 1}{s^{(t+1)}} \right) (x^{(t+1)} - x^{(t)})$
	\end{itemize}
	
	\newpage
	The method implementation is presented in the file $Part\_2.R$,
	\vspace{2mm}
	\lstinputlisting[language = R, firstline=95, lastline=144]{R_Code/Part_2.R}
	
	
	\newpage
	\textbf{Convergence Comparison}
	
		\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.8\linewidth]{R_Code/Convergency.png}
			\caption{\small Proximal Gradient Convergency Comparison
			}
		\end{center}
	\end{figure}


	\end{enumerate}

\end{document}


